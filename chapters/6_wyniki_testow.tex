\chapter{Wyniki testów}
Wyniki testów każdej aplikacji uruchamianej w poszczególnych przypadkach  testowych przedstawiono w formie diagramów: diagramu przedstawiającego liczbę żądań obsłużonych przez aplikację w ciągu sekundy i diagramu rozkładu czasów odpowiedzi aplikacji.

Wyniki testów podzielono na dwie grupy zależne  od początkowego stanu bazy danych.

\section{Testy z pustą bazą danych}

\subsection{Test wydajności walidacji API}
Wyniki testów wydajności walidujących istnienie klucza API przedstawiają diagramy zamieszczone na rysunkach \ref{fig:tomcat_clean_api_validation_rps} - \ref{fig:go_clean_api_validation_td}.

Z diagramów prezentujących liczbę żądań obsłużonych w ciągu sekundy przez poszczególne aplikacje (rys. \ref{fig:tomcat_clean_api_validation_rps}, \ref{fig:jetty_clean_api_validation_rps}, \ref{fig:go_clean_api_validation_rps}) wynika, że przy 100 klientach największą liczbę żądań obsłużyła aplikacja napisana w \textsl{Go} - od 9.0 do 11.0 tysięcy obsłużonych żądań. Wydajność serwera \textsl{Jetty} oscylowała w przedziale od 5.0 do 10.0 tysięcy obsłużonych żądań, przy znacznych wahaniach przepustowości. Przepustowość serwera Tomcat oscylowała w przedziale od 6.0 do 8.0 tysięcy obsłużonych żądań. Przy 250 klientach wydajność aplikacji w Go oscylowała w przedziale od 8.0 do 10.0 tysięcy obsłużonych żądań, a serwery Jetty i Tomcat obsłużyły od 4.0 do 8.0 tysięcy żądań przy dużych wahaniach przepustowości.      

Z diagramów rozkładu czasów odpowiedzi aplikacji (rys. \ref{fig:tomcat_clean_api_validation_td}, \ref{fig:jetty_clean_api_validation_td}, \ref{fig:go_clean_api_validation_td}) wynika, że przy 100 klientach średnie czasy odpowiedzi wynosiły: dla serwera Tomcat 8 13.70 milisekund, dla serwera Jetty 11.42 milisekund, a dla aplikacji w Go 9,44 milisekundy. Najdłużej trwające żądania trwały około 35 milisekund w przypadku serwerów Tomcat i Jetty oraz 18 milisekund przy aplikacji w Go. Przy 250 klientach średnie czasy odpowiedzi aplikacji uruchamianych na serwerach Tomcat i Jetty były prawie takie same i wynosiły odpowiednio 36.32 i 35.52 milisekund, a w aplikacji w Go 22t.47 milisekundy. Najdłużej trwające żądania trwały ponad 90 milisekund w przypadku serwera Tomcat, poniżej 88 milisekund w przypadku serwera Jetty i około 55 milisekundy przy aplikacji w Go. Dodatkowo, przy 250 klientach, dla serwerów Tomcat i Jetty rozkłady czasów odpowiedzi były spłaszczone. 

% \input{chapters/5_testy_wydajnosciowe_diagram_1_clean_api_validation.tex}
\clearpage

\subsection{Test wydajności walidacji istnienia obiektów Cache}
Wyniki testów wydajności walidacji istnienia obiektów Cache przedstawiają diagramy na rysunkach \ref{fig:tomcat_clean_key_validation_rps} - \ref{fig:go_clean_key_validation_td}.              

Z diagramów przedstawiających rozkład ilości żądań obsłużonych przez poszczególne aplikacje w ciągu sekundy  (rys. \ref{fig:tomcat_clean_key_validation_rps} \ref{fig:jetty_clean_key_validation_rps}, \ref{fig:go_clean_key_validation_rps}) wynika, że przy 100 klientach największą liczbę żądań (około 7.0 tysięcy) obsłużyła aplikacja napisana w \textsl{Go}. Wydajność serwera \textsl{Jetty} oscylowała w przedziale od 3.5 do 4.5 tysiąca obsłużonych żądań, a serwera Tomcat w przedziale od 2.0 do 3.5 tysiąca obsłużonych żądań. Przy 250 klientach wydajność aplikacji w Go oscylowała w przedziale od 7.0 do 8.0 tysięcy obsłużonych żądań, serwer Jetty obsłużył około 3.0 tysięcy żądań, a serwer Tomcat od 2.0 do 3.5 tysiąca żądań.

Z diagramów rozkładu czasów odpowiedzi (rys. \ref{fig:tomcat_clean_key_validation_td}, \ref{fig:jetty_clean_key_validation_td}, \ref{fig:go_clean_key_validation_td}) wynika, że przy 100 klientach średnie czasy odpowiedzi wynosiły: dla serwera Tomcat 30.32 milisekund, dla serwera Jetty 23.32 milisekund, a dla aplikacji w Go 13.79 milisekund. Najdłużej trwające żądania trwały około 120 milisekund w przypadku serwera Tomcat, 45 milisekund przy Jetty i tylko 25 milisekund w aplikacji w Go. Przy 250 klientach średnie czasy odpowiedzi aplikacji uruchamianych na serwerach Tomcat i Jetty wynosiły odpowiednio 69.97 i 76.92 milisekundy, a w aplikacji w Go tylko 30.75 milisekundy. Najdłużej trwające żądania trwały 250 milisekund w przypadku serwera Tomcat, okło 120 milisekund w przypadku serwera Jetty i tylko 65 milisekundy przy aplikacji w Go. Czasy odpowiedzi serwera Tomcat w sporej części o były dużo dłuższe niż pokazuje to średnia.

% \input{chapters/5_testy_wydajnosciowe_diagram_2_clean_key_validation.tex}
\clearpage

\subsection{Test wydajności operacji CRUD}
Wyniki testów wydajności operacji CRUD przedstawiają diagramy na rysunkach \ref{fig:tomcat_clean_crud_rps} - \ref{fig:go_clean_crud_td}.

Z diagramów przedstawiających rozkład ilości żądań obsłużonych przez poszczególne aplikacje w ciągu sekundy (rys. \ref{fig:tomcat_clean_crud_rps}, \ref{fig:jetty_clean_crud_rps}, \ref{fig:go_clean_crud_rps}) wynika, że przy przy 100 klientach największą liczbę żądań obsłużyła aplikacja napisana w \textsl{Go} - od 4.0 do 5.0 tysięcy. Serwer \textsl{Jetty} obsługiwał ponad 2.2 tysiące żądań, a przepustowość serwera Tomcat oscylowała w przedziale od 2.0 do 2.5 tysiąca obsłużonych żądań. Przy 250 klientach aplikacja w Go obsłużyła od 4.5 do 6.0 tysięcy żądań, serwer Jetty około 2.0 tysięcy żądań, podobnie jak serwer Tomcat.

Z diagramów rozkładu czasów odpowiedzi (rys. \ref{fig:tomcat_clean_crud_td}, \ref{fig:jetty_clean_crud_td}, \ref{fig:go_clean_crud_td}) wynika, że przy 100 klientach średnie czasy odpowiedzi wynosiły: dla serwera Tomcat 42.15  milisekund, dla serwera Jetty 42.41  milisekund i 20.90 milisekund dla aplikacji w Go.  Najdłużej trwające żądania trwały poniżej 80 milisekund w przypadku serwerów Tomcat i Jetty - jednak \textsl{Jetty} miał większą liczbę obsłużonych żądań. Dla aplikacji w \textsl{Go} najdłużej trwające żądania trwały tylko 35 milisekund. Przy 250 klientach średnie czas odpowiedzi aplikacji uruchamianych na serwerach Tomcat i Jetty  wynosiły  odpowiednio 107.56 i 92.32 milisekund, a w aplikacji w Go tylko 35.68 milisekundy. Najdłużej trwające żądania trwały 200 milisekund w przypadku serwera Tomcat, 180 milisekund w przypadku serwera Jetty i 90 milisekund przy aplikacji w Go. 

% \input{chapters/5_testy_wydajnosciowe_diagram_3_clean_crud.tex}
\clearpage

\subsection{Test wydajności walidacji API, obiektów Cache oraz operacji CRUD równolegle}
Diagramy zawierające wyniki wydajności walidacji API, obiektów Cache oraz operacji CRUD równolegle zamieszczono na rys. \ref{fig:tomcat_clean_all_rps} - \ref{fig:go_clean_all_td}.                                                                  

Z rozkładów ilości żądań obsłużonych przez poszczególne aplikacje w ciągu sekundy (rys. \ref{fig:tomcat_clean_all_rps}, \ref{fig:jetty_clean_all_rps}, \ref{fig:go_clean_all_rps}) wynika, że przy 100 klientach największą liczbę żądań obsłużyła aplikacja napisana w \textsl{Go} - od 7.0 do 8.0 tysięcy, a serwery \textsl{Jetty} i Tomcat obsługiwały od 3.0 do 4.0  tysięcy żądań. Przy 250 klientach aplikacja w Go obsłużyła również od 7.0 do 8.0 tysięcy żądań, serwer Jetty 3.0 tysiące, a wydajność serwera Tomcat oscylowała na poziomie 2.5 tysiąca żądań. 
 
Z diagramów rozkładu czasów odpowiedzi (rys. \ref{fig:tomcat_clean_all_td}, \ref{fig:jetty_clean_all_td}, \ref{fig:go_clean_all_td}) wynika, że przy 100 klientach średnie czasy odpowiedzi wynosiły: dla serwera Tomcat 27.30  milisekund, dla serwera Jetty 25.63 milisekund i 13.94 milisekund dla aplikacji w Go.  Najdłużej trwające żądania trwały poniżej 110 milisekund w przypadku serwera Tomcat, powyżej 60 milisekund przy Jetty i około 35 milisekund  w aplikacji w Go. Przy 250 klientach średnie czas odpowiedzi aplikacji uruchamianych na serwerach Tomcat i Jetty wynosiły 86.85 i 74.48 milisekund, a w aplikacji w Go tylko 28.06 milisekundy. Najdłużej trwające żądania trwały poniżej 180 milisekund w przypadku serwera Tomcat, 150 milisekund w przypadku serwera Jetty i 85 milisekund przy aplikacji w Go. 

% \input{chapters/5_testy_wydajnosciowe_diagram_4_clean_all.tex}
\clearpage

\newpage
\section{Testy z bazą wypełnioną danymi początkowymi}
\subsection{Testy wydajności walidacji API}
Diagramy zawierające wyniki wydajności walidacji API zamieszczono na rysunkach \ref{fig:tomcat_full_api_validation_rps} - \ref{fig:go_full_api_validation_td}

Z rozkładów ilości żądań obsłużonych przez poszczególne aplikacje w ciągu sekundy (rys. rys. \ref{fig:tomcat_full_api_validation_rps} \ref{fig:jetty_full_api_validation_rps}, \ref{fig:go_full_api_validation_rps}) wynika, że przy 100 klientach aplikacja  w \textsl{Go} obsługiwała od 9.0 do 10.0 tysięcy żądań. Wydajność serwera  \textsl{Jetty} oscylowała w przedziale od 8.0 do 10.0 tysięcy żądań. Serwer Tomcat obsługiwał od 5.0 do 7.0 tysięcy żądań. Przy 250 klientach aplikacja w Go obsługiwała również od 8.0 do 10.0 tysięcy żądań, serwer Jetty od 4.0 do 8.5 tysiąca żądań przy bardzo dużych wahaniach przepustowości, a wydajność serwera Tomcat oscylowała w przedziale od 3.0 do 6.0 tysiąca obsłużonych żądań. 
 
Z diagramów rozkładu czasów odpowiedzi (rys. \ref{fig:tomcat_full_api_validation_td}, \ref{fig:jetty_full_api_validation_td}, \ref{fig:go_full_api_validation_td}) wynika, że przy 100 klientach średnie czasy odpowiedzi wynosiły: dla serwera Tomcat 16.72 milisekund, dla serwera Jetty 10.25 milisekund i 10.24 milisekund dla aplikacji w Go. Najdłużej trwające żądania trwały poniżej 45 milisekund przy serwerze Tomcat, 30 milisekund przy Jetty i 18 milisekund w aplikacji w Go. Przy 250 klientach średnie czasy odpowiedzi aplikacji uruchamianych na serwerach Tomcat iJetty wynosiły odpowiednio 67.28 i 47.00 milisekundy, a w aplikacji w Go 25.33 milisekundy. Najdłużej trwające żądania trwały poniżej 110 milisekund w przypadku serwera Tomcat, 83 milisekundy w przypadku serwera Jetty i 55 milisekund przy aplikacji w Go. 

% \input{chapters/5_testy_wydajnosciowe_diagram_5_full_api_validation.tex}
\clearpage

\subsection{Test wydajności walidacji istnienia obiektów Cache}
Wyniki testów wydajności walidacji istnienia obiektów Cache przedstawiają diagramy na rysunkach \ref{fig:tomcat_full_key_validation_rps} - \ref{fig:go_full_key_validation_td}.              

Z diagramów przedstawiających rozkład ilości żądań obsłużonych przez poszczególne aplikacje w ciągu sekundy  (rys. \ref{fig:tomcat_full_key_validation_rps} \ref{fig:jetty_full_key_validation_rps}, \ref{fig:go_full_key_validation_rps}) wynika, że przy 100 klientach przepustowość aplikacji w \textsl{Go} kształtowała się w przedziale od 5.0 do 6.0 tysięcy żądań. Należy zaznaczyć, że przepustowość ta została osiągniętą po upływie 3 minut od rozpoczęcia testu. Wydajność serwera \textsl{Jetty} oscylowała w przedziale od 4.0 do 5.0 tysięcy obsłużonych żądań, a serwera Tomcat od 2.0 do 3.0 tysięcy obsłużonych żądań. Przy 250 klientach aplikacja w Go obsłużyła od 5.0 do 6.0 tysięcy żądań również po upływie 3 minut od rozpoczęcia testu, serwer Jetty około 3.0 tysięcy żądań, a serwer Tomcat od 2.0 do 3.0 tysiąca żądań.

Z diagramów rozkładu czasów odpowiedzi (rys. \ref{fig:tomcat_full_key_validation_td}, \ref{fig:jetty_full_key_validation_td}, \ref{fig:go_full_key_validation_td}) wynika, że przy 100 klientach średnie czasy odpowiedzi wynosiły: dla serwera Tomcat 38.00 milisekund, dla serwera Jetty 22.15 milisekund i 19.75 milisekund dla aplikacji w Go. Najdłużej trwające żądania trwały 150 milisekund przy serwerze Tomcat, około 40 milisekund na serwerze Jetty i tyle samo w aplikacji w Go. Przy 250 klientach średnie czasy odpowiedzi aplikacji uruchamianych na serwerach Tomcat i Jetty wynosiły 86.73 i 82.37 milisekundy, a w aplikacji w Go 40.66 milisekundy. Najdłużej trwające żądania trwały 250 milisekund w przypadku serwera Tomcat, 120 milisekund w przypadku serwera Jetty i poniżej 100  milisekund przy aplikacji w Go. 

% \input{chapters/5_testy_wydajnosciowe_diagram_6_full_key_validation.tex}
\clearpage

\subsection{Test wydajności operacji CRUD}

Wyniki testów wydajności walidacji istnienia operacji CRUD przedstawiają diagramy na rysunkach \ref{fig:tomcat_full_crud_rps} - \ref{fig:go_full_crud_td}.

Z diagramów przedstawiających rozkład ilości żądań obsłużonych przez poszczególne aplikacje w ciągu sekundy (rys. \ref{fig:tomcat_full_crud_rps} \ref{fig:jetty_full_crud_rps}, \ref{fig:go_full_crud_rps}) wynika, że przy 100 i 250 klientach poszczególne aplikacje zachowywały się porównywalnie. Przepustowość aplikacji w \textsl{Go} wahała się na od 0.5 do 3.0 tysięcy obsłużonych żądań, serwer \textsl{Jetty} obsługiwał od 0.5 do ponad 2.0 tysięcy żądań, a serwer Tomcat od 0.5 do około 1.5 tysiąca żądań. Dla każdej z aplikacji występowały spadki przepustowości nawet poniżej 500 żądań/s.

Z diagramów rozkładu czasów odpowiedzi (rys. \ref{fig:tomcat_full_crud_td}, \ref{fig:jetty_full_crud_td}, \ref{fig:go_full_crud_td}) wynika, że przy 100 klientach średnie czasy odpowiedzi wynosiły: dla serwera Tomcat 61.57 milisekund, dla serwera Jetty 50.04 milisekundy i 32.26 milisekund dla aplikacji w Go. Najdłużej trwające żądania trwały poniżej 130 milisekund przy serwerze Tomcat, 0koło 100 milisekund przy serwerze Jetty i poniżej 70 milisekund w aplikacji w Go. Przy 250 klientach średnie czasy odpowiedzi aplikacji uruchamianych na serwerach Tomcat i Jetty  wynosiły odpowiednio 128.07 i 101.60 milisekund, a w aplikacji w Go tylko 48.96 milisekundy. Najdłużej trwające żądania trwały około 300 milisekund w przypadku serwera Tomcat, 240 milisekund w przypadku serwera Jetty i poniżej 170 milisekund przy aplikacji w Go. 

\input{chapters/5_testy_wydajnosciowe_diagram_7_full_crud.tex}
\clearpage

\subsection{Test wydajności walidacji API, obiektów Cache oraz operacji CRUD równolegle }

Wyniki testów wydajności walidacji API, obiektów Cache oraz operacji CRUD równolegle przedstawiają diagramy na rysunkach \ref{fig:tomcat_full_all_rps} - \ref{fig:go_full_all_td}.              

Z diagramów przedstawiających rozkład ilości żądań obsłużonych przez poszczególne aplikacje w ciągu sekundy  (rys. \ref{fig:tomcat_full_all_rps} \ref{fig:jetty_full_all_rps}, \ref{fig:go_full_all_rps}) wynika, że przy 100 klientach przepustowość aplikacja w \textsl{Go} kształtowała się w przedziale od 4.0 do 6.0 tysięcy obsłużonych żądań, wydajność serwera \textsl{Jetty} oscylowała w przedziale od 3.0 do 3.5 tysiąca  żądań, a  serwera Tomcat  obsłużył od 2.5 do 3.0 tysięcy żądań. Przy 250 klientach aplikacja w Go obsłużyła również od 4.0 do 6.0 tysięcy żądań, a przepustowość serwerów Jetty i Tomcat oscylowała w przedziale od 2.0 do 3.0 tysięcy żądań. Dla każdej z aplikacji występowały spadki przepustowości nawet poniżej 500 żądań/s

Z diagramów rozkładu czasów odpowiedzi (rys. \ref{fig:tomcat_full_all_td}, \ref{fig:jetty_full_all_td}, \ref{fig:go_full_all_td}) wynika, że przy 100 klientach średnie czasy odpowiedzi wynosiły: dla serwera Tomcat 35.82 milisekundy, dla serwera Jetty 30.10 milisekund i 19.40 milisekund dla aplikacji w Go. Najdłużej trwające żądania trwały poniżej 100 milisekund przy serwerze Tomcat, 80 milisekund przy serwerze Jetty i  poniżej 50 milisekund  w aplikacji w Go. Przy 250 klientach średnie czasy odpowiedzi aplikacji uruchamianych na serwerach Tomcat  i Jetty   wynosiły odpowiednio 96.96 i 82.34 milisekundy, a w aplikacji w Go tylko 38.33 milisekundy. Najdłużej trwające żądania trwały poniżej 200 milisekund w przypadku serwerów Tomcat i Jetty oraz 130 milisekund w teście aplikacji w Go. 

\input{chapters/5_testy_wydajnosciowe_diagram_8_full_all.tex}
\clearpage

\section{Obciążenie maszyn wirtualnych}

\newpage
\section{Podsumowanie wyników}
